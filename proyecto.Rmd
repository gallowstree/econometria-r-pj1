---
title: "Proyecto HousePrices :P"
output: html_notebook
---
# Librerías
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(cleandata)
library(corrplot)
library(gridExtra)
library(Metrics)
library(caret)
library(MASS)
library(robustbase)
library(cvTools)

```

# Pre-procesamiento, limpieza y análisis inicial
```{r}

median_house_value_scale = 10000

initialPreprocessing<-function(df) {
  df$ocean_proximity<-as.factor(df$ocean_proximity)
  
  op_order<-c("INLAND", "<1H OCEAN", "NEAR OCEAN","NEAR BAY", "ISLAND")
  enc_ocean_proximity<-encode_ordinal(data.frame(enc_ocean_proximity=df[["ocean_proximity"]]), order=op_order, out.int=T, full_print = F)
  df<-cbind(df, enc_ocean_proximity=enc_ocean_proximity)
  
  if("median_house_value" %in% colnames(df)) {
      df$median_house_value<-df$median_house_value / median_house_value_scale
  }
  
  return(df)
}

loadAndPreprocess<-function(csvName) {
  return(initialPreprocessing(read.csv(csvName)))
}

all_data=loadAndPreprocess("train.csv")
all_data
```

Es bastante claro que al menos en cierta medida, la proximidad al océano afecta el precio. Esto nos da una pista de que podemos codificar esta variable como ordinal. Movimos esto a nuestra función de pre-procesamiento arriba para aprovecharlo en cualquier dataset.
```{r eval=FALSE}
all_data %>% 
  group_by(ocean_proximity) %>%
  summarize(mean_value = mean(median_house_value)) %>%
  arrange(desc(mean_value))
```


Usamos summary para ver cuáles columnas tienen NAs y verificamos el valor mínimo de cada columna para asegurarnos que no hay NAs disfrazados de 0

```{r fig.width=12}
summary(all_data)
```

Solamente total_bedrooms tiene faltantes y son 144, veamos cuánto es eso en porcentaje.

```{r}
naCount<-sum(is.na(all_data$total_bedrooms))

naCount / length(all_data$total_bedrooms) * 100
```

Prácticamente 1% de datos faltantes. Nos ocuparemos de ellos, pero antes debemos divir los datos en train/test
```{r}
set.seed(279720)
spec = c(train = .80, validate = .20)
#spec = c(train = .7, test = .15, validate = .15)

g = sample(cut(
  seq(nrow(all_data)), 
  nrow(all_data)*cumsum(c(0,spec)),
  labels = names(spec)
))

data = split(all_data, g)
```


```{r}
nasRemoved<-data$train %>% 
  dplyr::select(-c(ocean_proximity, id)) %>%
  filter(!is.na(total_bedrooms))
         
corrplot(cor(nasRemoved), 
         method = "ellipse", 
         type="full",
        addCoef.col = rgb(0,0,0, alpha = 0.6), diag = TRUE, number.cex=0.77, 
        col= colorRampPalette(c("red","white", "green"))(100))
```

# Imputación
Vemos que nuestra variable con NAs (total_bedrooms) tiene correlación casi perfecta con households, por lo que usaremos el valor de esta para obtener datos de imputación. 

```{r}

imp_total_bedrooms<-function(df, traindata=nasRemoved) {
  x<-traindata$households
  y<-traindata$total_bedrooms
  lr<-lm(y ~ x)
  new<-data.frame(x = df$households)
  
  df$total_bedrooms<-as.integer(ifelse(is.na(df$total_bedrooms), 
                                predict(lr, new), 
                                df$total_bedrooms))
  
  return(df)
}

data$train<-imp_total_bedrooms(data$train)
data$validate<-imp_total_bedrooms(data$validate)

print(summary(data$train$total_bedrooms))
print(summary(data$validate$total_bedrooms))

```



# Outliers pt.1
```{r fig.height=4, fig.width=12.5}
plot_outliers<-function(df, colname) {
  column<-sym(colname)

  hist<-ggplot(df, aes(x=unlist(!!column)))+
    geom_histogram(color="white", fill="blue")+
    theme_minimal()
  
  box<-ggplot(df, aes(x=unlist(!!column)))+
    geom_boxplot()+
    theme_minimal()
  
  
  qq<-ggplot(df, aes(sample=!!column))+
    stat_qq()+
    stat_qq_line(col="red", lwd=1)
    theme_minimal()

  grid.arrange(hist, box, qq, ncol=3)
}
```


```{r fig.height=4, fig.width=12.5, eval=FALSE}
for (col in names(nasRemoved)) {
  plot_outliers(nasRemoved, col)
}
```


# Creación y análisis de nuevos features

```{r eval=FALSE, fig.width=7.5, }
beds_per_rooms<-data$train$total_bedrooms / data$train$total_rooms
rooms_per_household<-data$train$total_rooms / data$train$households
income_per_capita<-data$train$median_income/data$train$population
income_per_household<-data$train$median_income/data$train$households
beds_per_capita<-data$train$total_bedrooms / data$train$population
rooms_per_capita<-data$train$total_rooms / data$train$population
pop_per_household<-data$train$population/data$train$households # check this one agian after doing something with the outliers
pop_per_bedroom<-data$train$population/data$train$total_bedrooms
pop_per_room<-data$train$population/data$train$total_rooms

candidates<-data.frame(beds_per_rooms, rooms_per_household, income_per_capita, income_per_household, beds_per_capita, rooms_per_capita, pop_per_household, pop_per_bedroom, pop_per_room, data$train$median_house_value)

summary(candidates)
corrplot(cor(candidates), 
         method = "ellipse", 
         type="full",
        addCoef.col = rgb(0,0,0, alpha = 0.6), diag = TRUE, number.cex=0.7,  tl.cex=0.75 , 
        col= colorRampPalette(c("red","white", "green"))(100))
```


```{r}

addExtraFeats<-function(df) {
  if("beds_per_rooms" %in% colnames(df)) { 
    return(df)
  }
  
  beds_per_rooms<-df$total_bedrooms / df$total_rooms
  rooms_per_household<-df$total_rooms / df$households
  income_per_capita<-df$median_income/df$population
  income_per_household<-df$median_income/df$households
  beds_per_capita<-df$total_bedrooms / df$population
  rooms_per_capita<-df$total_rooms / df$population
  pop_per_household<-df$population/df$households  # check this one agian after doing something with the outliers
  
  return(cbind(df, beds_per_rooms, rooms_per_capita, rooms_per_household, income_per_capita))
}

```

```{r}
data$train<-addExtraFeats(data$train)
data$validate<-addExtraFeats(data$validate)
```

# Entrenamiento de modelo pt.1

```{r}
model_rmse<-function(model, observations, actual_values, scale=median_house_value_scale) {
  predictions<-predict(model, observations)
  return(rmse(predictions, actual_values)*scale)
}
```

```{r}
training_vars_1<-data$train %>%
  dplyr::select(median_house_value, 
                median_income,
                enc_ocean_proximity,
                total_rooms,
                latitude,
                longitude,
                total_bedrooms,
                housing_median_age,
                beds_per_rooms,
                rooms_per_capita,
                rooms_per_household,
                income_per_capita)

fit1<-lm(median_house_value ~ ., data = training_vars_1)

```

```{r}

scores<-function(model, xs=data$validate, y=data$validate$median_house_value) {
  folds <- cvFolds(nrow(xs), K = 5, R = 10)
  return(data.frame(
    validation_error=model_rmse(model, xs, y),
    k_fold_cv_error=repCV(model, cost = rmspe, folds = folds)$cv[[1]]*median_house_value_scale
  ))
}

scores(fit1)

```

# Outliers pt.2
## plots
```{r eval=FALSE}
outlier_values <- boxplot.stats(data$train$total_rooms)$out  # outlier values.
boxplot(data$train$total_rooms, main="total_rooms", boxwex=0.1)
print(outlier_values)

outlier_values <- boxplot.stats(data$train$total_bedrooms)$out  # outlier values.
boxplot(data$train$total_bedrooms, main="total_bedrooms", boxwex=0.1)
print(outlier_values)

outlier_values <- boxplot.stats(data$train$population)$out  # outlier values.
boxplot(data$train$population, main="population", boxwex=0.1)
print(outlier_values)

outlier_values <- boxplot.stats(data$train$households)$out  # outlier values.
boxplot(data$train$households, main="households", boxwex=0.1)
print(outlier_values)

outlier_values <- boxplot.stats(data$train$median_income)$out  # outlier values.
boxplot(data$train$median_income, main="median_income", boxwex=0.1)
print(outlier_values)

outlier_values <- boxplot.stats(data$train$median_house_value)$out  # outlier values.
boxplot(data$train$median_house_value, main="median_house_value", boxwex=0.1)
print(outlier_values)
```

## cook's distance
```{r fig.height=7, fig.width=9}
cooksd<-cooks.distance(fit1)
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```

```{r}
distances<-data.frame(d=cooksd[cooksd>4*mean(cooksd, na.rm=T)])
distances<-distances %>% arrange(desc(d))
indices<-as.integer(row.names(distances))
indices

data$train[match(indices, rownames(data$train)),]
# 7589, 13996, 8834, 6377, 5815, 7589, 8919, 3137

```
## outliers test
```{r}
car::outlierTest(fit1)
```

# Entrenamiento de modelos sin outliers
```{r fig.height=10, fig.width=10, eval=FALSE}
train_with_extras<-train_with_extras[-match(indices[1:20], rownames(train_with_extras)),]




fit11_ <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + w1 + w2 + w3 +w4, data=train_with_extras)

cooksd<-cooks.distance(fit11_)
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels

car::outlierTest(fit11_)

```

# Entrenamiento de modelos robustos 

```{r}



```
 
# Predicciones en test-set

```{r}
timestamp<-function() {
  my_options <- options(digits.secs = 3)
  timestamp<-strftime(Sys.time(), "%m%d_%H%M%OS")
  options(my_options)  
  return(timestamp)
}

writePredictions<-function(predictions, name, ids=testing_set$id) {
  data<-cbind(id=ids, median_house_value=predictions*median_house_value_scale)
  filename<-paste("predictions/", timestamp(), "_", name, ".csv", sep="")
  write.csv(data, filename, row.names = FALSE, quote=FALSE)
}
```

```{r}
testing_set<-loadAndPreprocess("test.csv")
testing_set<-imp_total_bedrooms(testing_set)
testing_set<-addExtraFeats(testing_set)
# writePredictions(predict(fit11, xs_test_ex), "fit11")
```

